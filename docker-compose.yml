services:
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1
    ports:
    - "8080:8080"
    - "50051:50051"
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'
      CLUSTER_HOSTNAME: 'node1'
    depends_on:
      - vllm-embedding

  vllm-embedding:
    image: vllm/vllm-openai:latest
    ports:
      - "8000:8000"
    command:
      - --model
      - BAAI/bge-small-en-v1.5
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - --served-model-name
      - bge-small-en-v1.5
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
    volumes:
      - vllm_cache:/root/.cache/huggingface
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  weaviate_data:
  vllm_cache:
